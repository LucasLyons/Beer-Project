{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf333602",
   "metadata": {},
   "source": [
    "# Model Training\n",
    "## Simple Neighbourhood Approach (User/Item Collaborative Filtering)\n",
    "As a first step, we will use basic neighbourhood-based collaborative filtering (CF) techniques (user and item based), with a simple model as a baseline. Here we implement user and item-based CF as described in Chapter 4 of *Recommender Systems Handbook, 3rd Ed.* (Ricci et. al, 2022)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de69b10",
   "metadata": {},
   "source": [
    "### Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "29db0925",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "import scipy as sp\n",
    "import scipy.stats as stats\n",
    "import powerlaw as pl\n",
    "import kagglehub\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "import duckdb as db\n",
    "import recbole as rb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "7c6d5a90",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27.4M/27.4M [00:00<00:00, 79.3MB/s]\n"
     ]
    }
   ],
   "source": [
    "# Download latest version of data\n",
    "path = kagglehub.dataset_download(\"rdoume/beerreviews\", path='beer_reviews.csv', force_download = True)\n",
    "beer = pd.read_csv(path)\n",
    "#remove nulls\n",
    "beer = beer[-beer.isna().any(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac37d1e",
   "metadata": {},
   "source": [
    "#### Multiple reviews for the same item\n",
    "We found earlier that there were around 14000 instances of a user reviewing the same beer more than once. Since basic collaborative filtering frameworks only account for a single user-item interaction, we need to specify an approach for dealing with these cases. In our simple model, we'll take the most recent rating as the \"true\" value. Later we'll experiment with different approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "19f26916",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's make a new dataframe\n",
    "beer_simple = beer.copy()\n",
    "# sort by the relevant columns\n",
    "beer_simple = beer_simple.sort_values(by=['review_profilename', 'beer_beerid', 'review_time'])\n",
    "# keep only the most recent review for the user-beer key\n",
    "beer_simple = beer_simple.drop_duplicates(subset=['review_profilename', 'beer_beerid'], keep=\"last\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "f7799a1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_profilename</th>\n",
       "      <th>beer_beerid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [review_profilename, beer_beerid]\n",
       "Index: []"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test using SQL\n",
    "query = \"SELECT review_profilename, beer_beerid \\\n",
    "    FROM beer_simple GROUP BY review_profilename, beer_beerid\\\n",
    "    HAVING COUNT(*)>1 \\\n",
    "    ORDER BY review_profilename, beer_beerid\"\n",
    "#use duckdb to query the data\n",
    "db.sql(query).df()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc00d85",
   "metadata": {},
   "source": [
    "#### Threshold Choice\n",
    "We're going to look at the performance of models using several different thresholds for review counts. There are some different considerations to make. First of all, we saw from the EDA that many beers and users only have one review - this is the cold start problem. To construct a meaningful collaborative filter model, we'll need at least three reviews per user/item. In the special case of using 3 as a threshold, we'll have to forgo the validation set entirely so that we have multiple data points per user/item. We'll investigate how different thresholds affect the tradeoff between coverage of recommended items and the quality of recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "767ad0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set thresholds\n",
    "t = [3,5,10,20,50]\n",
    "raw_data = []\n",
    "for i in t:\n",
    "    #create dataframes for users and beers with at least i reviews\n",
    "    df = beer_simple.groupby('review_profilename').filter(lambda x: x.shape[0] >= i)\n",
    "    df = df.groupby('beer_beerid').filter(lambda x: x.shape[0] >= i)\n",
    "    #append\n",
    "    raw_data.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec52072",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "brewery_id               3313\n",
       "brewery_name             3272\n",
       "review_time           1447995\n",
       "review_overall             10\n",
       "review_aroma                9\n",
       "review_appearance          10\n",
       "review_profilename      18596\n",
       "beer_style                104\n",
       "review_palate               9\n",
       "review_taste                9\n",
       "beer_name               24099\n",
       "beer_abv                  437\n",
       "beer_beerid             25946\n",
       "dtype: int64"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data[0].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "366573d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "brewery_id                819\n",
       "brewery_name              818\n",
       "review_time           1055884\n",
       "review_overall              9\n",
       "review_aroma                9\n",
       "review_appearance           9\n",
       "review_profilename       4706\n",
       "beer_style                103\n",
       "review_palate               9\n",
       "review_taste                9\n",
       "beer_name                4628\n",
       "beer_abv                  244\n",
       "beer_beerid              4713\n",
       "dtype: int64"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data[4].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e03afc1",
   "metadata": {},
   "source": [
    "Observe the difference in unique `beer_beerid` and `review-profilename`. As we saw during the EDA, we're going to lose a lot of coverage when we look at the high threshold data sets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5836e0ea",
   "metadata": {},
   "source": [
    "#### Data Splitting\n",
    "Now that we've cleaned our data and we have our datasets for different thresholds, it's time to split our data. We'll split our data \"manually\". We're going to leave the last rating as a test - we'll try and predict a user's *next* rating using all their past ratings as training data. This data splitting method approximates many real-world use cases, where we might want to predict a user's future behaviour given their actions until the current time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7332714e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18596\n",
      "14600\n",
      "10574\n",
      "7580\n",
      "4706\n"
     ]
    }
   ],
   "source": [
    "test = []\n",
    "for i in range(5):\n",
    "    #keep the last review for each user\n",
    "    test.append(raw_data[i].drop_duplicates(subset=['review_profilename'], keep=\"last\"))\n",
    "    print(test[-1].shape[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
