{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bde68b44",
   "metadata": {},
   "source": [
    "# Surprise SVD\n",
    "To benchmark our manual SVD implementation, we'll train the SVD model from `surprise` on the same data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6892638a",
   "metadata": {},
   "source": [
    "## Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae1e9331",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add project root to Python path\n",
    "project_root = os.path.abspath(\"..\")\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "# import packages\n",
    "from utils.imports import *\n",
    "# import user-defined funcs and classes\n",
    "from utils.helpers import plot_heatmap\n",
    "from utils.helpers import get_top_n\n",
    "from utils.helpers import top_n_coverage\n",
    "from utils.helpers import round_half"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "378266f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas dataframes\n",
    "with open(\"../data/dataframes.pkl\", \"rb\") as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "train = data[\"train\"]\n",
    "validation = data[\"validation\"]\n",
    "baseline = data[\"baseline\"]\n",
    "\n",
    "# load sparse matrix\n",
    "ui_csr = load_npz(\"../data/ui_csr.npz\")\n",
    "\n",
    "# load encodings\n",
    "with open(\"../artifacts/user_encoder.pkl\", \"rb\") as f:\n",
    "    user_encoder = pickle.load(f)\n",
    "with open(\"../artifacts/item_encoder.pkl\", \"rb\") as f:\n",
    "    item_encoder = pickle.load(f)\n",
    "with open(\"../artifacts/user_map.pkl\", \"rb\") as f:\n",
    "    user_map = pickle.load(f)\n",
    "with open(\"../artifacts/item_map.pkl\", \"rb\") as f:\n",
    "    item_map = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff9a7097",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import surprise tools\n",
    "from surprise import SVD, Dataset, Reader, accuracy\n",
    "from surprise.model_selection import cross_validate, GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7bae56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create reader\n",
    "reader = Reader(rating_scale=(0, 5))\n",
    "# generate surprise data\n",
    "train_ds = Dataset.load_from_df(\n",
    "    train[['user_idx', \"item_idx\", \"review_overall\"]], reader)\n",
    "# create set for training surprise model\n",
    "trainset = train_ds.build_full_trainset()\n",
    "# format validation set for testing\n",
    "valset = list(zip(validation['user_idx'],\n",
    "                  validation['item_idx'],\n",
    "                  validation['review_overall']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0789931e",
   "metadata": {},
   "source": [
    "## Grid Search\n",
    "We'll perform a grid search over the same grid of hyperparameters we searched in the manual SVD implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b93210",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set parameter grid\n",
    "k_grid = np.array([25,50,75,100]) # set k grid\n",
    "reg_grid = np.array([0.001, 0.02, 0.1]) # set reg grid\n",
    "grid = itertools.product(k_grid, reg_grid)\n",
    "surprise_models = []\n",
    "# dataframe for grid search\n",
    "surprise_grid_search = pd.DataFrame(columns=('reg', 'k', 'RMSE', 'MAE', 'coverage'))\n",
    "for k, reg in grid:\n",
    "    # fit model with grid params\n",
    "    model = SVD(n_factors=k, reg_all=reg)\n",
    "    model.fit(trainset)\n",
    "    # test on validation set\n",
    "    preds = model.test(valset)\n",
    "    # we need to calculate RMSE and MAE on the rounded predictions\n",
    "    rounded_preds = []\n",
    "    for pred in preds:\n",
    "        est = min(max(pred.est, model.trainset.rating_scale[0]), model.trainset.rating_scale[1])  # clip\n",
    "        est_rounded = round_half(est)\n",
    "        # create a new Prediction object with rounded value\n",
    "        rounded_preds.append(pred._replace(est=est_rounded))\n",
    "    # compute accuracy metrics on rounded predictions\n",
    "    rmse = accuracy.rmse(rounded_preds, verbose=False)\n",
    "    mae = accuracy.mae(rounded_preds, verbose=False)\n",
    "    # evaluate coverage\n",
    "    N = 10\n",
    "    coverage = top_n_coverage(model, trainset, N) # get training set item catalog coverage @ top 10 beers\n",
    "    # add results to dataframe\n",
    "    surprise_grid_search.loc[len(surprise_grid_search)]= (reg, k, rmse, mae, coverage)\n",
    "    # save model\n",
    "    surprise_models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac12a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save results of grid search\n",
    "with open(\"../artifacts/surprise_models.pkl\", \"wb\") as f:\n",
    "   pickle.dump(surprise_models, f)\n",
    "with open(\"../data/surprise_grid_search.pkl\", \"wb\") as f:\n",
    "   pickle.dump(surprise_grid_search, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
