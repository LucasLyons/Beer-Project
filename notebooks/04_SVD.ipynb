{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b9fc3ec",
   "metadata": {},
   "source": [
    "# Learning Model (SVD)\n",
    "Now that we've implemented naive user-based CF, we'll implement a more advanced model - the SVD model.\n",
    "\n",
    "INSERT DESCRIPTION HERE\n",
    "\n",
    "One disadvantage of the SVD model is that it can't generalize to unseen items - predictions rely on item and user factors which are learned during model training. When training our model, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "addea3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add project root to Python path\n",
    "project_root = os.path.abspath(\"..\")\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "# import packages\n",
    "from utils.imports import *\n",
    "# import user-defined funcs and classes\n",
    "from utils.helpers import plot_heatmap\n",
    "from models.ManualSVD import ManualSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81debd6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas dataframes\n",
    "with open(\"../data/dataframes.pkl\", \"rb\") as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "train = data[\"train\"]\n",
    "validation = data[\"validation\"]\n",
    "baseline = data[\"baseline\"]\n",
    "\n",
    "# load sparse matrix\n",
    "ui_csr = load_npz(\"../data/ui_csr.npz\")\n",
    "\n",
    "# load encodings\n",
    "with open(\"../artifacts/user_encoder.pkl\", \"rb\") as f:\n",
    "    user_encoder = pickle.load(f)\n",
    "with open(\"../artifacts/item_encoder.pkl\", \"rb\") as f:\n",
    "    item_encoder = pickle.load(f)\n",
    "with open(\"../artifacts/user_map.pkl\", \"rb\") as f:\n",
    "    user_map = pickle.load(f)\n",
    "with open(\"../artifacts/item_map.pkl\", \"rb\") as f:\n",
    "    item_map = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd40ad8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# this grid search takes a long time to run so it's quoted out\n",
    "\n",
    "\"\"\"k_grid = np.array([25,50,75, 100]) # set k grid\n",
    "reg_grid = np.array([0.001, 0.02, 0.1]) # set reg grid\n",
    "grid = itertools.product(k_grid, reg_grid)\n",
    "models = []\n",
    "# dataframe for grid search\n",
    "grid_search = pd.DataFrame(columns=('reg', 'k', 'RMSE', 'MAE', 'coverage', 'hit_rate'))\n",
    "for k, reg in grid:\n",
    "    # fit model with grid params\n",
    "    model = ManualSVD(k=k, reg=reg)\n",
    "    model.fit(ui_csr, validation, verbose=False)\n",
    "    #evaluate\n",
    "    N_1, N_2 = 100, 10\n",
    "    hit_rate = model.hit_rate_at_N(validation, N_1) # get hit rate @ top 100 beers\n",
    "    coverage = model.top_N_coverage(N_2) # get training set item catalog coverage @ top 10 beers\n",
    "    # add results to dataframe\n",
    "    grid_search.loc[len(grid_search)]= (reg, k, model.RMSE_clipped, model.MAE, coverage, hit_rate)\n",
    "    # save model\n",
    "    models.append(model)\n",
    "    print('\\n')\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df53b3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save results of grid search\n",
    "with open(\"../artifacts/models.pkl\", \"wb\") as f:\n",
    "   pickle.dump(models, f)\n",
    "with open(\"../data/grid_search.pkl\", \"wb\") as f:\n",
    "   pickle.dump(grid_search, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
